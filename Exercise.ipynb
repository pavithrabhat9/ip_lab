{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low pass spatial filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\\\IMAGES\\\\fort.jpg\",0)\n",
    "m,n=img.shape\n",
    "mask=np.ones([3,3],dtype=int)\n",
    "mask=mask/9\n",
    "img_new=np.zeros([m,n])\n",
    "for i in range(1,m-1):\n",
    "    for j in range(1,n-1):\n",
    "        temp=img[i-1,j-1]*mask[0,0]+img[i-1,j]*mask[0,1]+img[i-1,j+1]*mask[0,2]+img[i,j-1]*mask[1,0]+img[i,j]*mask[1,1]+img[i,j+1]*mask[1,2]+img[i+1,j-1]*mask[2,0]+img[i+1,j]*mask[2,1]+img[i+1,j+1]*mask[2,2]\n",
    "        img_new[i,j]=temp\n",
    "img_new=img_new.astype(np.uint8)\n",
    "cv2.imwrite('Blurred.tif',img_new)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Blurred image\",img_new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median spatial filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "img_noisy=cv2.imread(\"D:\\\\IMAGES\\\\fort.jpg\",0)\n",
    "m,n=img.shape\n",
    "img_new1=np.zeros([m,n])\n",
    "for i in range(1,m-1):\n",
    "    for j in range(1,n-1):\n",
    "        temp=[img_noisy[i-1,j-1],\n",
    "              img_noisy[i-1,j],\n",
    "              img_noisy[i-1,j+1],\n",
    "              img_noisy[i,j-1],\n",
    "              img_noisy[i,j],\n",
    "              img_noisy[i,j+1],\n",
    "              img_noisy[i+1,j-1],\n",
    "              img_noisy[i+1,j],\n",
    "              img_noisy[i+1,j+1]]\n",
    "        temp=sorted(temp)\n",
    "        img_new1[i,j]=temp[4]\n",
    "img_new1=img_new1.astype(np.uint8)\n",
    "cv2.imwrite(\"New_median_filtered.png\",img_new1)\n",
    "cv2.imshow(\"Original image\",img_noisy)\n",
    "cv2.imshow(\"Blurred image\",img_new1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\\\IMAGES\\\\fort.jpg\",0)\n",
    "height,width=img.shape\n",
    "filter_img=np.zeros((height,width),dtype=np.uint8)\n",
    "kernel_size=4\n",
    "padding=kernel_size//2\n",
    "for i in range(padding,height-padding):\n",
    "    for j in range(padding,width-padding):\n",
    "        neighborhood=img[i-padding:i+padding+1,j-padding:j+padding+1]\n",
    "        median_val=np.median(neighborhood)\n",
    "        filter_img[i,j]=int(median_val)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Filtered image\",filter_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\\\IMAGES\\\\fort.jpg\",0)\n",
    "height,width=img.shape\n",
    "filter_img=np.zeros((height,width),dtype=np.uint8)\n",
    "kernel_size=3\n",
    "padding=kernel_size//2\n",
    "for i in range(padding,height-padding):\n",
    "    for j in range(padding,width-padding):\n",
    "        nei=img[i-padding:i+padding+1,j-padding:j+padding+1]\n",
    "        mean_val=np.mean(nei)\n",
    "        filter_img[i,j]=mean_val\n",
    "print(nei)\n",
    "print(mean_val)        \n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Filtered image\",filter_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d52408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Canny edge\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "blur_img=cv2.GaussianBlur(img,(5,5),0)\n",
    "#Apply canny edge detection\n",
    "edges=cv2.Canny(blur_img,threshold1=50,threshold2=50)\n",
    "#Display the original image and canny edge detection result\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Canny edge detection\",edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobel edge detection\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\J0099165.JPG\")\n",
    "#blur the image for better edge detection\n",
    "img_blur=cv2.GaussianBlur(img,(3,3),0)\n",
    "#sobel edge detection\n",
    "sobelx=cv2.Sobel(src=img_blur,ddepth=cv2.CV_64F,dx=1,dy=0,ksize=5)\n",
    "sobely=cv2.Sobel(src=img_blur,ddepth=cv2.CV_64F,dx=0,dy=1,ksize=5)\n",
    "sobelxy=cv2.Sobel(src=img_blur,ddepth=cv2.CV_64F,dx=1,dy=1,ksize=5)\n",
    "#display\n",
    "plt.figure()\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img),plt.title(\"Original image\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(sobelx),plt.title(\"sobel X\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobely),plt.title(\"sobel Y\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobelxy),plt.title(\"sobel X & Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prewitt edge detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "#blur the image for better edge detection\n",
    "gaus=cv2.GaussianBlur(img,(5,5),0)\n",
    "#kernel\n",
    "kernelx=np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernely=np.array([[-1,1,0],[-1,0,1],[-1,0,1]])\n",
    "prewittx=cv2.filter2D(gaus,-1,kernelx)\n",
    "prewitty=cv2.filter2D(gaus,-1,kernely)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Prewitt x\",prewittx)\n",
    "cv2.imshow(\"Prewitt y\",prewitty)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplacian\n",
    "import cv2\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "laplacian=cv2.Laplacian(img,cv2.CV_64F)\n",
    "#conver the result into 8-bit image\n",
    "laplacian_8bit=cv2.convertScaleAbs(laplacian)\n",
    "#display\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Laplacian edge detection\",laplacian_8bit)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local thresholding\n",
    "import cv2\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "#apply adaptive thresholding using opencv adaptive thershold function\n",
    "thresholded_img=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "#save the thresholded image\n",
    "cv2.imwrite(\"Thresholded_img.jpg\",thresholded_img)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Thresholded image\",thresholded_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global thresholding\n",
    "import cv2\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "#apply global thresholding using opencv thershold function\n",
    "_,thresholded_img=cv2.threshold(img,128,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Thresholded image\",thresholded_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ee4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum spatial filter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\hampi.jpg\",0)\n",
    "row,col=img.shape\n",
    "img_filter=np.zeros((row,col),dtype=np.uint8)\n",
    "for i in range(1,row-1):\n",
    "    for j in range(1,col-1):\n",
    "        neighbors=[]\n",
    "        for p in [-1,0,1]:\n",
    "            for q in [-1,0,1]:\n",
    "                neighbors.append(img[i+p][j+q])\n",
    "        img_filter[i][j]=max(neighbors)        \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.subplot(132)\n",
    "plt.title(\"Maaximum filter image\")\n",
    "plt.imshow(img_filter,cmap='gray')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimum spatial filter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\hampi.jpg\",0)\n",
    "row,col=img.shape\n",
    "img_filter=np.zeros((row,col),dtype=np.uint8)\n",
    "for i in range(1,row-1):\n",
    "    for j in range(1,col-1):\n",
    "        neighbors=[]\n",
    "        for p in [-1,0,1]:\n",
    "            for q in [-1,0,1]:\n",
    "                neighbors.append(img[i+p][j+q])\n",
    "        img_filter[i][j]=min(neighbors)        \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title(\"Minimum filter image\")\n",
    "plt.imshow(img_filter,cmap='gray')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean spatial filter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\hampi.jpg\",0)\n",
    "row,col=img.shape\n",
    "mask=np.ones([3,3],dtype=int)\n",
    "mask=mask/9\n",
    "img_filter=np.zeros([row,col],np.uint8)\n",
    "for i in range(1,row-1):\n",
    "    for j in range(1,col-1):\n",
    "        temp=0\n",
    "        for p in [-1,0,1]:\n",
    "            for q in [-1,0,1]:\n",
    "                temp=temp+(img[i+p,j+q]*mask[p+1,q+1])\n",
    "        img_filter[i][j]=temp        \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title(\"Mean filter image\")\n",
    "plt.imshow(img_filter,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd28db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using library mahotas\n",
    "from pylab import imshow,show\n",
    "import mahotas\n",
    "import mahotas.demos\n",
    "import numpy as np\n",
    "wally=mahotas.demos.load('Wally')\n",
    "wfloat=wally.astype(float)\n",
    "imshow(wally)\n",
    "show()\n",
    "r,g,b=wfloat.transpose((2,0,1))\n",
    "w=wfloat.mean(2)\n",
    "pattern=np.ones((24,16),float)\n",
    "for i in range(2):\n",
    "    pattern[i::4]=-1\n",
    "    v=mahotas.convolve(r-w,pattern)\n",
    "    mask=(v==v.max())\n",
    "    mask=mahotas.dilate(mask,np.ones((48,24)))\n",
    "    np.subtract(wally,.8*wally*~mask[:,:,None],out=wally,casting='unsafe')\n",
    "imshow(wally)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a29fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install python-pgmagick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image enhancement in frequency domain-fourier trnasform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt,exp\n",
    "plt.figure(figsize=(6.4*5,4.8*5),constrained_layout=False)\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "plt.subplot(151),plt.imshow(img,\"gray\"),plt.title(\"Original Image\")\n",
    "original=np.fft.fft2(img)\n",
    "plt.subplot(152),plt.imshow(np.log(1+np.abs(original)),\"gray\"),plt.title(\"Spectrum\")\n",
    "center=np.fft.fftshift(original)\n",
    "plt.subplot(153),plt.imshow(np.log(1+np.abs(center)),\"gray\"),plt.title(\"Centered Spectrum\")\n",
    "inv_center=np.fft.fftshift(center)\n",
    "plt.subplot(154),plt.imshow(np.log(1+np.abs(inv_center)),\"gray\"),plt.title(\"Decentered Spectrum\")\n",
    "processed_img=np.fft.ifft2(inv_center)\n",
    "plt.subplot(155),plt.imshow(np.abs(processed_img),\"gray\"),plt.title(\"Processed Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac78d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma Correction\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "#trying 5 gmama values\n",
    "for gamma in[0.1,0.5,1.2,2.2,5]:\n",
    "    #apply gamma correction\n",
    "    gamma_corrected=np.array((255*((img/255)**gamma)),dtype='uint8')\n",
    "    plt.subplot()\n",
    "    plt.imshow(cv2.cvtColor(gamma_corrected,cv2.COLOR_BGR2RGB))\n",
    "    plt.title(gamma)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain edge image without standard function\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import sqrt,exp\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\",0)\n",
    "height,width=img.shape\n",
    "edge_image=np.zeros_like(img)\n",
    "\n",
    "#Approximate gradients by calculating differences between adjacent pixels\n",
    "for i in range(1,height-1):\n",
    "    for j in range(1,width-1):\n",
    "        #Compute differences between adjacent pixels x and y direction\n",
    "        dx=int(img[i,j+1])-int(img[i,j-1])\n",
    "        dy=int(img[i+1,j])-int(img[i-1,j])\n",
    "        \n",
    "        #Gradient magnitude\n",
    "        edge_image[i,j]=min(255,np.sqrt(dx**2+dy**2))\n",
    "\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "cv2.imshow(\"Edge Image\",edge_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063341e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Histogram of three components- RGB,YIQ,HSI\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\IMAGES\\china.jpg\")\n",
    "\n",
    "#Convert to Grayscale and plot histogram\n",
    "gray_image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "plt.hist(gray_image.ravel(),256,[0,256],color='black')\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"Pixel value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "#Convert to RGB and plot histogram\n",
    "rgb_image=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "colors=(\"r\",\"g\",\"b\")\n",
    "plt.figure()\n",
    "for i,col in enumerate(colors):\n",
    "    hist=cv2.calcHist([rgb_image],[i],None,[256],[0,256])\n",
    "    plt.plot(hist,color=col)\n",
    "plt.title(\"RGB Histogram\")\n",
    "plt.xlabel(\"Pixel value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "#Convert to YIQ and plot histogram\n",
    "yiq_image=cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\n",
    "colors=(\"y\",\"c\",\"m\")\n",
    "plt.figure()\n",
    "for i,col in enumerate(colors):\n",
    "    hist=cv2.calcHist([yiq_image],[i],None,[256],[0,256])\n",
    "    plt.plot(hist,color=col)\n",
    "plt.title(\"YIQ Histogram\")\n",
    "plt.xlabel(\"Pixel value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "#Convert to HSI and plot histogram\n",
    "hsv_image=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "colors=(\"r\",\"g\",\"b\")\n",
    "plt.figure()\n",
    "for i,col in enumerate(colors):\n",
    "    hist=cv2.calcHist([hsv_image],[i],None,[256],[0,256])\n",
    "    plt.plot(hist,color=col)\n",
    "plt.title(\"HSI Histogram\")\n",
    "plt.xlabel(\"Pixel value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge detetion - Prewitt, Sobel, Laplacian\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"D:\\\\IMAGES\\\\fort.jpg\",0)\n",
    "#blur the image for better edge detection\n",
    "img_blur=cv2.GaussianBlur(img,(3,3),0)\n",
    "\n",
    "#sobel edge detection\n",
    "sobelx=cv2.Sobel(src=img_blur,ddepth=cv2.CV_64F,dx=1,dy=0,ksize=5)\n",
    "sobely=cv2.Sobel(src=img_blur,ddepth=cv2.CV_64F,dx=0,dy=1,ksize=5)\n",
    "sobelxy=cv2.Sobel(src=img_blur,ddepth=cv2.CV_64F,dx=1,dy=1,ksize=5)\n",
    "#display\n",
    "plt.figure()\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img),plt.title(\"Original image\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(sobelx),plt.title(\"sobel X\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobely),plt.title(\"sobel Y\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobelxy),plt.title(\"sobel X & Y\")\n",
    "\n",
    "#Prewitt edge detection-kernel\n",
    "kernelx=np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernely=np.array([[-1,1,0],[-1,0,1],[-1,0,1]])\n",
    "prewittx=cv2.filter2D(img_blur,-1,kernelx)\n",
    "prewitty=cv2.filter2D(img_blur,-1,kernely)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Prewitt x\",prewittx)\n",
    "cv2.imshow(\"Prewitt y\",prewitty)\n",
    "\n",
    "#Laplacian\n",
    "laplacian=cv2.Laplacian(img,cv2.CV_64F)\n",
    "#conver the result into 8-bit image\n",
    "laplacian_8bit=cv2.convertScaleAbs(laplacian)\n",
    "#display\n",
    "cv2.imshow(\"Laplacian edge detection\",laplacian_8bit)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image smoothing - median filtering,mean spatial filtering\n",
    "\n",
    "#median filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\\\IMAGES\\\\fort.jpg\",0)\n",
    "height,width=img.shape\n",
    "filter_img=np.zeros((height,width),dtype=np.uint8)\n",
    "kernel_size=4\n",
    "padding=kernel_size//2\n",
    "for i in range(padding,height-padding):\n",
    "    for j in range(padding,width-padding):\n",
    "        neighborhood=img[i-padding:i+padding+1,j-padding:j+padding+1]\n",
    "        median_val=np.median(neighborhood)\n",
    "        filter_img[i,j]=int(median_val)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Filtered image\",filter_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Mean spatial filter\n",
    "row,col=img.shape\n",
    "mask=np.ones([3,3],dtype=int)\n",
    "mask=mask/9\n",
    "img_filter=np.zeros([row,col],np.uint8)\n",
    "for i in range(1,row-1):\n",
    "    for j in range(1,col-1):\n",
    "        temp=0\n",
    "        for p in [-1,0,1]:\n",
    "            for q in [-1,0,1]:\n",
    "                temp=temp+(img[i+p,j+q]*mask[p+1,q+1])\n",
    "        img_filter[i][j]=temp        \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title(\"Mean filter image\")\n",
    "plt.imshow(img_filter,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line detection using Houhline method\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\IMAGES\\J0341455.JPG\")\n",
    "edges=cv2.Canny(img,75,150)\n",
    "lines=cv2.HoughLinesP(edges,1,np.pi/180,30,maxLineGap=250)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2=line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,128),1)\n",
    "cv2.imshow(\"LinesEdges\",edges)\n",
    "cv2.imshow(\"LinesDetected\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corner detection using Harries algorithm\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\IMAGES\\J0341455.JPG\")\n",
    "operatedImage=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "operatedImage=np.float32(operatedImage)\n",
    "dest=cv2.cornerHarris(operatedImage,2,5,0.07)\n",
    "dest=cv2.dilate(dest,None)\n",
    "img[dest>0.01*dest.max()]=[0,0,255]\n",
    "cv2.imshow(\"Image with borders\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51731fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourier transform 1D and 2D\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#2D Fourier transform\n",
    "img=cv2.imread(\"D:\\IMAGES\\J0341455.JPG\",0)\n",
    "\n",
    "#1D Fourier transform\n",
    "#Select a row from the image(middle row)\n",
    "row_index=img.shape[0]//2\n",
    "signal_1D=img[row_index,:]\n",
    "#Compute 1D Fourier transform\n",
    "fft_signal=np.fft.fft(signal_1D)\n",
    "freq=np.fft.fftfreq(len(signal_1D))\n",
    "mag_1D=np.abs(fft_signal)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(signal_1D)\n",
    "plt.title(\"Original signal\")\n",
    "plt.xlabel(\"Pixel position\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.stem(freq[:len(freq)//2],mag_1D[:len(mag_1D)//2],basefmt=\"\")\n",
    "plt.title(\"Magnitude of the Fourier transform \")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SimpleITK and Mahotas\n",
    "#Using library mahotas\n",
    "from pylab import imshow,show\n",
    "import mahotas\n",
    "import mahotas.demos\n",
    "import numpy as np\n",
    "wally=mahotas.demos.load('Wally')\n",
    "wfloat=wally.astype(float)\n",
    "imshow(wally)\n",
    "show()\n",
    "r,g,b=wfloat.transpose((2,0,1))\n",
    "w=wfloat.mean(2)\n",
    "pattern=np.ones((24,16),float)\n",
    "for i in range(2):\n",
    "    pattern[i::4]=-1\n",
    "    v=mahotas.convolve(r-w,pattern)\n",
    "    mask=(v==v.max())\n",
    "    mask=mahotas.dilate(mask,np.ones((48,24)))\n",
    "    np.subtract(wally,.8*wally*~mask[:,:,None],out=wally,casting='unsafe')\n",
    "imshow(wally)\n",
    "show()\n",
    "\n",
    "#Using library simpleITK\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "img=sitk.ReadImage(\"D:\\IMAGES\\headnneck.jpg\")\n",
    "#Convert simpleITK image to a numpy array for openCV compatibility\n",
    "img_array=sitk.GetArrayFromImage(img)\n",
    "#Access specific slice from the image array\n",
    "slice_index=2\n",
    "img_slice=img_array[:,:,slice_index]\n",
    "#Display the slice using openCV\n",
    "cv2.imshow(\"Original image\",img_array)\n",
    "cv2.imshow(\"Medical image slice\",img_slice)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def Canny_detector(img, weak_th = None, strong_th = None): \n",
    "\n",
    "    # conversion of image to grayscale \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Noise reduction step \n",
    "    img = cv2.GaussianBlur(img, (5, 5), 1.4) \n",
    "\n",
    "    # Calculating the gradients \n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1, 0, 3) \n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_64F, 0, 1, 3) \n",
    "\n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees = True) \n",
    "\n",
    "    # setting the minimum and maximum thresholds for double thresholding \n",
    "    mag_max = np.max(mag) \n",
    "    if not weak_th:weak_th = mag_max * 0.1\n",
    "    if not strong_th:strong_th = mag_max * 0.5\n",
    "\n",
    "    # getting the dimensions of the input image \n",
    "    height, width = img.shape \n",
    "\n",
    "    # Looping through every pixel of the grayscale image \n",
    "    for i_x in range(width): \n",
    "        for i_y in range(height): \n",
    "\n",
    "            grad_ang = ang[i_y, i_x] \n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang) \n",
    "\n",
    "            # selecting the neighbours of the target pixel according to the gradient direction in the x axis direction \n",
    "            if grad_ang<= 22.5: \n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y \n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y \n",
    "\n",
    "            # top right (diagonal-1) direction \n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45): \n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "\n",
    "            # In y-axis direction \n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90): \n",
    "                    neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                    neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "\n",
    "            # top left (diagonal-2) direction \n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135): \n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "\n",
    "            # Now it restarts the cycle \n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180): \n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y \n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y \n",
    "\n",
    "            # Non-maximum suppression step \n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0: \n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]: \n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "\n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0: \n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]: \n",
    "                    mag[i_y, i_x]= 0\n",
    "\n",
    "    weak_ids = np.zeros_like(img) \n",
    "    strong_ids = np.zeros_like(img)\n",
    "    ids = np.zeros_like(img) \n",
    "\n",
    "    # double thresholding step \n",
    "    for i_x in range(width): \n",
    "        for i_y in range(height): \n",
    "\n",
    "            grad_mag = mag[i_y, i_x] \n",
    "\n",
    "            if grad_mag<weak_th: \n",
    "                mag[i_y, i_x]= 0\n",
    "            elif strong_th>grad_mag>= weak_th: \n",
    "                ids[i_y, i_x]= 1\n",
    "            else: \n",
    "                ids[i_y, i_x]= 2\n",
    "\n",
    "\n",
    "    # finally returning the magnitude of gradients of edges \n",
    "    return mag \n",
    "\n",
    "frame = cv2.imread(\"D:\\IMAGES\\Gojo.jpg\") \n",
    "\n",
    "# calling the designed function for finding edges \n",
    "canny_img = Canny_detector(frame) \n",
    "\n",
    "# Displaying the input and output image \n",
    "plt.figure() \n",
    "f, plots = plt.subplots(2, 1) \n",
    "plots[0].imshow(frame) \n",
    "plots[1].imshow(canny_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d115b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sharpening and edge detection\n",
    "import numpy as np \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "fig=plt.figure(figsize=(15,8))\n",
    "row=2\n",
    "column=2\n",
    "img=cv2.imread(\"D:\\IMAGES\\photo.jpg\")\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Sharpening the image using different kernels\n",
    "sharpen_kernel=np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
    "edgedetection_kernel1=np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])\n",
    "edgedetection_kernel2=np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "identity_kernel1=np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "\n",
    "sharpen_image1=cv2.filter2D(src=img,ddepth=-1,kernel=sharpen_kernel)\n",
    "edgedetected_image1=cv2.filter2D(src=img,ddepth=-1,kernel=edgedetection_kernel1)\n",
    "edgedetected_image2=cv2.filter2D(src=img,ddepth=-1,kernel=edgedetection_kernel2)\n",
    "identity_image1=cv2.filter2D(src=img,ddepth=-1,kernel=identity_kernel1)\n",
    "\n",
    "fig.add_subplot(row,column,1)\n",
    "plt.imshow(sharpen_image1)\n",
    "plt.title(\"Sharpened image\")\n",
    "\n",
    "fig.add_subplot(row,column,2)\n",
    "plt.imshow(edgedetected_image1)\n",
    "plt.title(\"Edge detected image1\")\n",
    "\n",
    "fig.add_subplot(row,column,3)\n",
    "plt.imshow(edgedetected_image2)\n",
    "plt.title(\"Edge detected image2\")\n",
    "\n",
    "fig.add_subplot(row,column,4)\n",
    "plt.imshow(identity_image1)\n",
    "plt.title(\"Identity image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line and Corner detection\n",
    "#Line detection using Houhline method\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\IMAGES\\photo.jpg\")\n",
    "cv2.imshow(\"Original image\",img)\n",
    "edges=cv2.Canny(img,75,150)\n",
    "lines=cv2.HoughLinesP(edges,1,np.pi/180,30,maxLineGap=250)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2=line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,128),1)\n",
    "cv2.imshow(\"LinesEdges\",edges)\n",
    "cv2.imshow(\"LinesDetected\",img)\n",
    "\n",
    "#Corner detection using Harries algorithm\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\IMAGES\\photo.jpg\")\n",
    "operatedImage=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "operatedImage=np.float32(operatedImage)\n",
    "dest=cv2.cornerHarris(operatedImage,2,5,0.07)\n",
    "dest=cv2.dilate(dest,None)\n",
    "img[dest>0.01*dest.max()]=[0,0,255]\n",
    "cv2.imshow(\"Image with borders\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image enhancement in frequency domain-fourier trnasform\n",
    "#Fourier transform 2D\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt,exp\n",
    "plt.figure(figsize=(6.4*5,4.8*5),constrained_layout=False)\n",
    "img=cv2.imread(\"D:\\IMAGES\\photo.jpg\",0)\n",
    "plt.subplot(151),plt.imshow(img,\"gray\"),plt.title(\"Original Image\")\n",
    "original=np.fft.fft2(img)\n",
    "plt.subplot(152),plt.imshow(np.log(1+np.abs(original)),\"gray\"),plt.title(\"Spectrum\")\n",
    "center=np.fft.fftshift(original)\n",
    "plt.subplot(153),plt.imshow(np.log(1+np.abs(center)),\"gray\"),plt.title(\"Centered Spectrum\")\n",
    "inv_center=np.fft.fftshift(center)\n",
    "plt.subplot(154),plt.imshow(np.log(1+np.abs(inv_center)),\"gray\"),plt.title(\"Decentered Spectrum\")\n",
    "processed_img=np.fft.ifft2(inv_center)\n",
    "plt.subplot(155),plt.imshow(np.abs(processed_img),\"gray\"),plt.title(\"Processed Image\")\n",
    "plt.show()\n",
    "\n",
    "#Fourier transform 1D\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#2D Fourier transform\n",
    "img=cv2.imread(\"D:\\IMAGES\\photo.jpg\",0)\n",
    "\n",
    "#1D Fourier transform\n",
    "#Select a row from the image(middle row)\n",
    "row_index=img.shape[0]//2\n",
    "signal_1D=img[row_index,:]\n",
    "#Compute 1D Fourier transform\n",
    "fft_signal=np.fft.fft(signal_1D)\n",
    "freq=np.fft.fftfreq(len(signal_1D))\n",
    "mag_1D=np.abs(fft_signal)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(signal_1D)\n",
    "plt.title(\"Original signal\")\n",
    "plt.xlabel(\"Pixel position\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.stem(freq[:len(freq)//2],mag_1D[:len(mag_1D)//2],basefmt=\"\")\n",
    "plt.title(\"Magnitude of the Fourier transform \")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dinoising\n",
    "import cv2\n",
    "from skimage.restoration import denoise_tv_chambolle,denoise_bilateral\n",
    "from skimage.util import random_noise\n",
    "img=cv2.imread(\"D:\\IMAGES\\panda.jpg\")\n",
    "#Add noise to the image\n",
    "noisy_img=random_noise(img)\n",
    "denoised_img=denoise_tv_chambolle(noisy_img,multichannel=True)\n",
    "denoised_img2=denoise_bilateral(img,multichannel=True)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Noisy image\",noisy_img)\n",
    "cv2.imshow(\"Denoisy image\",denoised_img)\n",
    "cv2.imshow(\"Bilateral image\",denoised_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e96d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blurring an image using blur and gaussianblur function\n",
    "import cv2\n",
    "img=img=cv2.imread(\"D:\\IMAGES\\panda.jpg\")\n",
    "blurImg=cv2.blur(img,(10,10))\n",
    "blurred=cv2.GaussianBlur(img,(5,5),0)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "cv2.imshow(\"Blurred image\",blurImg)\n",
    "cv2.imshow(\"Gaussian Blurred image\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89868804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image,display\n",
    "img=cv2.imread(\"D:\\IMAGES\\images.jpeg\")\n",
    "cv2.imshow(\"Original\",img)\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\",gray)\n",
    "\n",
    "ret,bin_img=cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Binary inverse\",bin_img)\n",
    "\n",
    "kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "bin_img=cv2.morphologyEx(bin_img,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow(\"Binary morph\",bin_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(8,8))\n",
    "\n",
    "sure_bg=cv2.dilate(bin_img,kernel,iterations=3)\n",
    "#imshow(sure_bg,axes[0,0])\n",
    "#axes[0,0].set_title(\"Sure background\")\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Sure background\")\n",
    "plt.imshow(sure_bg)\n",
    "\n",
    "dist=cv2.distanceTransform(bin_img,cv2.DIST_L2,5)\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Distance\")\n",
    "plt.imshow(dist)\n",
    "#imshow(dist,axes[0,1])\n",
    "#axes[0,1].set_title(\"Distance transform\")\n",
    "\n",
    "ret,sure_fg=cv2.threshold(dist,0.5*dist.max(),255,cv2.THRESH_BINARY)\n",
    "sure_fg=sure_fg.astype(np.uint8)\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Sure Foreground\")\n",
    "plt.imshow(sure_fg)\n",
    "#imshow(sure_fg,axes[1,0])\n",
    "#axes[1,0].set_title(\"Sure Foreground\")\n",
    "\n",
    "unknown=cv2.subtract(sure_bg,sure_fg)\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"Unknown\")\n",
    "plt.imshow(unknown)\n",
    "#imshow(unknown,axes[1,1])\n",
    "#axes[1,1].set_title(\"Unknown\")\n",
    "plt.show()\n",
    "\n",
    "ret,markers=cv2.connectedComponents(sure_fg)\n",
    "\n",
    "markers+=1\n",
    "markers[unknown==255]=0\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "ax.imshow(markers,cmap=\"tab20b\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "markers=cv2.watershed(img,markers)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(5,5))\n",
    "ax.imshow(markers,cmap=\"tab20b\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "labels=np.unique(markers)\n",
    "coins=[]\n",
    "for label in labels[2:]:\n",
    "    target=np.where(markers==label,255,0).astype(np.uint8)\n",
    "    contours,heirarchy=cv2.findContours(target,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    coins.append(contours[0])\n",
    "img=cv2.drawContours(img,coins,-1,color=(0,23,223),thickness=2)\n",
    "cv2.imshow(\"FInal image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07af301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Active contour\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "img=data.astronaut()\n",
    "\n",
    "s=np.linspace(0,2*np.pi,400)\n",
    "x=220+100*np.cos(s)\n",
    "y=100+100*np.sin(s)\n",
    "init=np.array([x,y]).T\n",
    "\n",
    "cntr=active_contour(gaussian(img,3),init,alpha=0.015,beta=10,gamma=0.001)\n",
    "fig,ax=plt.subplots(1,2,figsize=(7,7))\n",
    "ax[0].imshow(img,cmap=plt.cm.gray)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "\n",
    "ax[1].imshow(img,cmap=plt.cm.gray)\n",
    "\n",
    "ax[1].plot(init[:,0],init[:,1],'--r',lw=3)\n",
    "ax[1].plot(cntr[:,0],cntr[:,1],'-b',lw=3)\n",
    "ax[1].set_title(\"Active contour image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread(\"D:\\IMAGES\\images.jpeg\")\n",
    "cv2.imshow(\"Original\",img)\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\",gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret,thresh=cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "plt.subplot(221),plt.imshow(thresh)\n",
    "kernel=np.ones((3,3),np.uint8)\n",
    "opening=cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "sure_bg=cv2.dilate(opening,kernel,iterations=3)\n",
    "dist=cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret,sure_fg=cv2.threshold(dist,0.7*dist.max(),255,0)\n",
    "sure_fg=np.uint8(sure_fg)\n",
    "unknown=cv2.subtract(sure_bg,sure_fg)\n",
    "ret,markers=cv2.connectedComponents(sure_fg)\n",
    "markers=markers+1\n",
    "markers[unknown==255]=0\n",
    "markers=cv2.watershed(img,markers)\n",
    "img[markers==-1]=[255,0,0]\n",
    "plt.subplot(222),plt.imshow(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete cosine transform\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"D:\\IMAGES\\Gojo.jpg\",0)\n",
    "imf=np.float32(img)\n",
    "dst=cv2.dct(imf,cv2.DCT_INVERSE)\n",
    "img1=cv2.idct(dst)\n",
    "img1=np.uint8(img)\n",
    "cv2.imshow(\"DCT\",dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"IDCT back image\",img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DCT-based image compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image compression\n",
    "import cv2\n",
    "import numpy as np\n",
    "def compress_image(image_path,quality=90):\n",
    "    img=cv2.imread(image_path)\n",
    "    encode_param=[int(cv2.IMWRITE_JPEG_QUALITY),quality]\n",
    "    _,encoded_img=cv2.imencode('.jpg',img,encode_param)\n",
    "    decoded_img=cv2.imdecode(encoded_img,cv2.IMREAD_COLOR)\n",
    "    return decoded_img\n",
    "org_img=cv2.imread(\"D:\\IMAGES\\panda.jpg\")\n",
    "compressed_img=compress_image(\"D:\\IMAGES\\panda.jpg\",quality=30)\n",
    "cv2.imshow(\"Original\",org_img)\n",
    "cv2.imshow(\"Compressed\",compressed_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huffman coding\n",
    "import heapq\n",
    "class node:\n",
    "    def __init__(self,freq,symbol,left=None,right=None):\n",
    "        self.freq=freq\n",
    "        self.symbol=symbol\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.huff=''\n",
    "    def __lt__(self,nxt):\n",
    "        return self.freq<nxt.freq\n",
    "def printNodes(node,val=''):\n",
    "    newval=val+str(node.huff)\n",
    "    if(node.left):\n",
    "        printNodes(node.left,newval)\n",
    "    if(node.right):\n",
    "        printNodes(node.right,newval)\n",
    "    if(not node.left and not node.right):\n",
    "        print(f\"{node.symbol}->{newval}\")\n",
    "        \n",
    "chars=['a','b','c','d','e','f']\n",
    "freq=[5,9,12,13,16,45]\n",
    "nodes=[]\n",
    "\n",
    "for x in range(len(chars)):\n",
    "    heapq.heappush(nodes,node(freq[x],chars[x]))\n",
    "    \n",
    "while len(nodes)>1:\n",
    "    left=heapq.heappop(nodes)\n",
    "    right=heapq.heappop(nodes)\n",
    "    left.huff=0\n",
    "    right.huff=1\n",
    "    newnode=node(left.freq+right.freq,left.symbol+right.symbol,left,right)\n",
    "    heapq.heappush(nodes,newnode)\n",
    "    \n",
    "printNodes(nodes[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete cosine transform and DPCM\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread(\"D:\\IMAGES\\photo.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "imf=np.float32(image)*255.0\n",
    "dst=cv2.dct(imf)\n",
    "imf_back=np.uint8(imf)/255.0\n",
    "#dct=cv2.dct(imf,DCT_INVERSE)\n",
    "#image=np.float32(image)\n",
    "#dct=cv2.dct(image)\n",
    "# Q=np.array([[16,11,10,16,24,40,51,61],\n",
    "#             [12,12,14,19,26,58,60,65],\n",
    "#             [14,13,16,24,40,57,69,56],\n",
    "#             [14,17,22,29,51,87,80,62],\n",
    "#             [18,22,37,56,68,109,103,77],\n",
    "#             [24,35,55,64,81,104,113,92],\n",
    "#             [49,64,78,87,103,121,120,101],\n",
    "#             [72,92,95,98,112,100,103,99]],dtype=np.float32)\n",
    "\n",
    "#quantized_dct=np.round(dct/Q)\n",
    "#dequantized_dct=quantized_dct*Q\n",
    "idct1=cv2.idct(dst)\n",
    "idct1=np.clip(idct1,0,255)\n",
    "idct1=np.uint8(image)\n",
    "\n",
    "# reconstucted_image=cv2.idct(dequantized_dct)\n",
    "# reconstucted_image=np.clip(reconstucted_image,0,255)\n",
    "# reconstucted_image=np.uint(reconstucted_image)\n",
    "cv2.imshow(\"Original image\",np.uint8(image))\n",
    "cv2.imshow(\"DCT\",dst)\n",
    "cv2.imshow(\"Quantization\",imf)\n",
    "cv2.imshow(\"Dequantization\",imf_back)\n",
    "cv2.imshow(\"Compressed image\",idct1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DPCM\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def dpcm_encode(image):\n",
    "    \"\"\"Encodes an image using DCM(Differential Pulse Code MOdulation)\"\"\"\n",
    "    rows,cols=image.shape\n",
    "    encoded=np.zeros((rows,cols),dtype=np.int16)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if j==0:\n",
    "                encoded[i,j]=image[i,j]\n",
    "            else:\n",
    "                encoded[i,j]=image[i,j]-image[i,j-1]\n",
    "    return encoded\n",
    "\n",
    "def dpcm_decode(encoded):\n",
    "    \"\"\"Decodes a DPCM-encoded image\"\"\"\n",
    "    rows,cols=encoded.shape\n",
    "    decoded=np.zeros((rows,cols),dtype=np.uint8)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if j==0:\n",
    "                decoded[i,j]=encoded[i,j]\n",
    "            else:\n",
    "                decoded[i,j]=np.clip(decoded[i,j-1]+encoded[i,j],0,255)\n",
    "    return decoded\n",
    "\n",
    "image=cv2.imread(\"D:\\\\IMAGES\\\\panda.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "en_img=dpcm_encode(image)\n",
    "de_img=dpcm_decode(en_img)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(image,cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"DPCM encoded\")\n",
    "plt.imshow(en_img,cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"DPCM decoded\")\n",
    "plt.imshow(de_img,cmap='gray')\n",
    "\n",
    "plt.show()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b564442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of the image restoration technique- weiner filtering\n",
    "import cv2\n",
    "Ioriginal=imread(\"D:\\IMAGES\\panda.jpg\")\n",
    "imshow(Ioriginal)\n",
    "title(\"Original Image\")\n",
    "PSF=fspecial(\"motion\",21,11)\n",
    "Idouble=im2double(Ioriginal)\n",
    "blurred=imfilter(Idouble,PSF,\"conv\",\"circular\")\n",
    "imshow(blurred)\n",
    "title(\"Blurred Image\")\n",
    "\n",
    "wnr1=deconvwnr(blurred,PSF)\n",
    "imshow(wnr1)\n",
    "title(\"Restored blurred image\")\n",
    "noise_mean=0\n",
    "noise_var=0.0001\n",
    "blurred_noisy=imnoise(blurred,\"gaussian\",noise_mean,noise_var)\n",
    "imshow(blurrednoisy)\n",
    "title(\"Blurred and noisy image\")\n",
    "\n",
    "wnr2=deconvwnr(blurred_noisy,PSF)\n",
    "imshow(wnr2)\n",
    "title(\"Restoration o blurred noisy image(NSR=0)\")\n",
    "signalvar=var(Idouble(:))\n",
    "NSR=noise_var/signal_var\n",
    "\n",
    "wnr3=deconvwnr(blurred_noisy,PSF,NSR)\n",
    "imshow(wnr3)\n",
    "title(\"Restoration of blurred noisy image(Estimated NSR)\")\n",
    "blurred_quantized=imfilter(Ioriginsl,PSF,\"conv\",\"circular\")\n",
    "imshow(blurred_quantized)\n",
    "title(\"Blurred quantized image\")\n",
    "\n",
    "wnr4=deconvwnr(blurred_quantized,PSF)\n",
    "imshow(wnr4)\n",
    "title(\"Restoration o blurred quantized image(NSR=0)\")\n",
    "\n",
    "uniform_quantization_var=(1/256)^2/12\n",
    "signal_var=var(Idouble(:))\n",
    "NSR=uniform_quantization_var/signal_var\n",
    "wnr5=econvwnr(blurred_quantized,PSF,NSR)\n",
    "imshow(wnr5\n",
    "title(\"Restoration o blurred quantized image(Estimated NSR)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huffman coding\n",
    "import cv2\n",
    "import numpy as np\n",
    "import heapq\n",
    "from collections import Counter\n",
    "img=cv2.imread(\"D:\\\\IMAGES\\\\panda.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "freq=Counter(img.flatten())\n",
    "heap=[[freq[pixel],pixel]for pixel in freq]\n",
    "heapq.heapify(heap)\n",
    "while len(heap)>1:\n",
    "    left,right=heapq.heappop(heap),heapq.heappop(heap)\n",
    "    heapq.heappush(heap,[left[0]+right[0],[left,right]])\n",
    "    \n",
    "huffman_codes={}\n",
    "def generate_codes(node,code=\"\"):\n",
    "    if isinstance(node[1],list):\n",
    "        generate_codes(node[1][0],code+\"0\")\n",
    "        generate_codes(node[1][1],code+\"1\")\n",
    "    else: \n",
    "        huffman_codes[node[1]]=code\n",
    "generate_codes(heap[0])\n",
    "encoded_img=\"\".join(huffman_codes[p] for p in image.flatten())\n",
    "reverse_map={v:k for k,v in huffman_codes.items()}\n",
    "decoded_pixel,temp=[],\"\"\n",
    "for bit in encoded_image:\n",
    "    temp+=bit\n",
    "    if temp in reverse_map:\n",
    "        decode_pixels.append(reverse_map[temp])\n",
    "        temp=\"\"\n",
    "decoded_image=np.array(decoded_pixels,dtype=np.uint8).reshape(img.shape)        \n",
    "cv2.imshow(\"Original\",img)\n",
    "cv2.imshow(\"Decoded\",decoded_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f9366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverse filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "for kernals in range(1,5):\n",
    "    kernal_filename='blur_kernals/kernal'+str(kernals)+'_'+str(kernals)+'.png'\n",
    "    h=cv2.imread(kernal_filename,0)\n",
    "    for images in range(1,5):\n",
    "        img_fn='blurry_images/blurry'+str5(images)+'_'+str(kernals)+'.png'\n",
    "        img_bgr=cv2.imread(img_fn)\n",
    "        restored=np.zeros(img_bgr.shape)\n",
    "        \n",
    "        print(img_fn)\n",
    "        print(kernal_filename)\n",
    "        \n",
    "        for i in range(0,3):\n",
    "            g=img_bgr[:,:,i]\n",
    "            G=(np.fft.fft2(g))\n",
    "            h_padded=np.zeros(g.shape)\n",
    "            h_padded[:h.shape[0],:h.shape[1]]=np.copy(h)\n",
    "            H=(np.fft.fft2(h_padded))\n",
    "            \n",
    "            H_norm=H/abs(H.max())\n",
    "            G_norm=G/abs(G.max())\n",
    "            F_temp=G_norm/H_norm\n",
    "            F_norm=F_temp/abs(F_temp.max())\n",
    "            \n",
    "            F_hat=F_norm*abs(G.max())\n",
    "            f_hat=np.fft.ifft2(F_hat)\n",
    "            restored[:,:,i]=abs(f_hat)\n",
    "            \n",
    "    out_fn='image_metrics/restored_'+str(images)+'_'+str(kernals)+'_1'+'.png'\n",
    "    cv2.imwrite(out_fn,restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplotas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e3f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
